{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f6ce8806-2471-4d5a-82f3-8eaa919acbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5486ad65-51f2-41eb-b322-41d1815cfc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.keras.backend.random_bernoulli(shape = (1,), p = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5b6d1035-630d-4554-911f-107d7a836262",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "X, y = np.reshape(np.array(train.iloc[:,1:]), (-1, 28,28 ,1)), train.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "676047d4-c91c-4bb1-86ac-2d43bfd7ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, random_state=42, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "93d2f67b-d260-4cd0-8d97-aa3e91fae1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train, dtype = 'float32')\n",
    "X_val = tf.convert_to_tensor(X_val, dtype = 'float32')\n",
    "y_train = tf.convert_to_tensor(y_train, dtype = 'float32')\n",
    "y_val = tf.convert_to_tensor(y_val, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "64c192d9-c06a-4877-8a50-8672b6740f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spatial_Gating_Unit(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_patches:int, initial_stddev:float):\n",
    "        super(Spatial_Gating_Unit, self).__init__()\n",
    "        self.n_patches = n_patches\n",
    "        self.initial_stddev = initial_stddev\n",
    "        \n",
    "        self.ln = tf.keras.layers.LayerNormalization()\n",
    "        self.t = tf.keras.layers.Permute((2,1))\n",
    "        self.Wb = tf.keras.layers.Dense(int(self.n_patches), kernel_initializer = tf.keras.initializers.RandomNormal(stddev=self.initial_stddev), bias_initializer = 'ones')\n",
    "        self.M = tf.keras.layers.Multiply()\n",
    "        \n",
    "    def call(self, X):\n",
    "        z1, z2 = tf.split(X, 2, axis=-1)\n",
    "        z2 = self.ln(z2)\n",
    "        z2 = self.t(z2)\n",
    "        z2 = self.Wb(z2)\n",
    "        z2 = self.t(z2)\n",
    "        X = self.M([z1,z2])\n",
    "        return X\n",
    "        \n",
    "        \n",
    "class gMLPs_Block(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model:int, patch_size:int, initial_stddev:float, d_ffn:int, survival_prob:float):\n",
    "        super(gMLPs_Block, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.patch_size = patch_size\n",
    "        self.initial_stddev = initial_stddev\n",
    "        self.d_ffn = d_ffn\n",
    "        self.survival_prob = survival_prob\n",
    "        \n",
    "        self.ln = tf.keras.layers.LayerNormalization()\n",
    "        self.U = tf.keras.layers.Dense(self.d_ffn, activation = 'gelu', kernel_initializer = tf.keras.initializers.lecun_normal())\n",
    "        self.SGU = Spatial_Gating_Unit(self.patch_size, self.initial_stddev)\n",
    "        self.V = tf.keras.layers.Dense(self.d_model, kernel_initializer = tf.keras.initializers.glorot_normal())\n",
    "        \n",
    "    def call(self, X):\n",
    "        y = self.ln(X)\n",
    "        y = self.U(y)\n",
    "        y = self.SGU(y)\n",
    "        y = self.V(y)\n",
    "        y = y * tf.keras.backend.random_bernoulli(shape = (1,), p = self.survival_prob)\n",
    "        y = X + y\n",
    "        # U : [batchs, patch_size^2, d_ffn] -> SGU : [batch, patch_size^2, d_ffn/2] -> V : [batch, patch_size^2, d_models] \n",
    "        return y\n",
    "    \n",
    "class gMLPs(tf.keras.models.Model):\n",
    "    def __init__(self, d_model:int, d_ffn:int, image_size:int, patch_size:int, n_res_layers:int, n_labels:int,\n",
    "                 survival_prob = 1., initial_stddev:float = 0.00001, mode:str = 'softmax'):\n",
    "        super(gMLPs, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ffn = d_ffn\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        if (self.image_size % self.patch_size) != 0:\n",
    "            raise ValueError('size error')\n",
    "        self.n_patches = int((tf.square(self.image_size) / tf.square(self.patch_size)).numpy())\n",
    "        self.n_res_layers = n_res_layers\n",
    "        self.n_labels = n_labels\n",
    "        self.initial_stddev = initial_stddev\n",
    "        if mode not in ['sigmoid','softmax']:\n",
    "            raise ValueError('mode must be sigmoid or softmax')\n",
    "        else:\n",
    "            self.mode = mode\n",
    "        self.survival_prob = survival_prob\n",
    "        \n",
    "        self.patchConv = tf.keras.layers.Conv2D(self.d_model, (self.patch_size, self.patch_size), strides = (self.patch_size, self.patch_size))\n",
    "        self.reshapeL = tf.keras.layers.Reshape((self.n_patches, self.d_model,))\n",
    "        self.gMLPBlocks = [gMLPs_Block(self.d_model, self.n_patches, self.initial_stddev, self.d_ffn, self.survival_prob) for x in range(self.n_res_layers)]\n",
    "        self.gap = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        self.classifier = tf.keras.layers.Dense(self.n_labels if self.n_labels > 2 else 1, activation = mode, kernel_initializer = tf.keras.initializers.glorot_normal(seed = 42))\n",
    "        \n",
    "    def call(self, X):\n",
    "        X = self.patchConv(X)\n",
    "        X = self.reshapeL(X)\n",
    "        for gMLPB in self.gMLPBlocks:\n",
    "            X = gMLPB(X)\n",
    "        X = self.gap(X)\n",
    "        X = self.classifier(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cdfb793b-87f0-429a-8936-9a4ab047b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmlp = gMLPs(256, 1536, 28, 4, 30, 10,\n",
    "            survival_prob = .95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "07787b60-e22e-49b1-8021-06a32cc7d761",
   "metadata": {},
   "outputs": [
    {
     "ename": "AlreadyExistsError",
     "evalue": "Another profiler is running.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-e2182f4552fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m             )\n\u001b[0;32m      5\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"logs/fit/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtensorboard_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m gmlp.fit(X_train, y_train, validation_data=(X_val, y_val), epochs = 10000,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, log_dir, histogram_freq, write_graph, write_images, update_freq, profile_batch, embeddings_freq, embeddings_metadata, **kwargs)\u001b[0m\n\u001b[0;32m   2067\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings_freq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings_metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2069\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_profile_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2070\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2071\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_global_train_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_init_profile_batch\u001b[1;34m(self, profile_batch)\u001b[0m\n\u001b[0;32m   2280\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_batch\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2281\u001b[0m       \u001b[1;31m# Warm up and improve the profiling accuracy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2282\u001b[1;33m       \u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2283\u001b[0m       \u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2284\u001b[0m     \u001b[1;31m# True when a trace is running.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\profiler\\profiler_v2.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(logdir, options)\u001b[0m\n\u001b[0;32m    113\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0m_profiler_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_profiler\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m       raise errors.AlreadyExistsError(None, None,\n\u001b[0m\u001b[0;32m    116\u001b[0m                                       'Another profiler is running.')\n\u001b[0;32m    117\u001b[0m     \u001b[0m_profiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_profiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProfilerSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAlreadyExistsError\u001b[0m: Another profiler is running."
     ]
    }
   ],
   "source": [
    "gmlp.compile(tf.keras.optimizers.Adam(0.0005),\n",
    "             loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics = 'accuracy'\n",
    "            )\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', restore_best_weights=True, patience=3)\n",
    "gmlp.fit(X_train, y_train, validation_data=(X_val, y_val), epochs = 10000,\n",
    "        callbacks = [es, tensorboard_callback], batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877780cc-ba65-4114-a418-e5a2ece4e906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
